# ðŸš€ Build ELT with Apache Airflow + dbt + Snowflake  
*A complete data pipeline for automated stock analytics*

This project demonstrates a production-style **ELT workflow** using:

- ðŸŒ€ **Apache Airflow (Docker)** for orchestration  
- ðŸ“ˆ **YFinance** for stock market data extraction  
- â„ï¸ **Snowflake** as the cloud data warehouse  
- ðŸ§± **dbt** for transformation, modeling, tests, and snapshots  
- ðŸ’¾ **GitHub** for versioning & collaboration

---

## ðŸ”¥ Architecture

```mermaid
graph LR
A[YFinance API] -->|Extract| B(Airflow ETL)
B -->|Load RAW Data| C[Snowflake RAW Layer]
C -->|Transform Models| D[dbt - Analytics Layer]
D -->|Tests + Quality| E[dbt Test]
E -->|Historical Tracking| F[dbt Snapshot]
F -->|Analytics Ready| G[BI Tools]

---


LAB2_Group_10/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ Lab2_ELT_with_DBT.py        # Airflow DAG (dbt run â†’ test â†’ snapshot)
â”‚
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ LAB2_Group_10/
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ raw_stocks_data.sql                  # Creates view from RAW layer
â”‚       â”‚   â”œâ”€â”€ stock_metrics/
â”‚       â”‚   â”‚   â”œâ”€â”€ moving_avg.sql
â”‚       â”‚   â”‚   â”œâ”€â”€ price_momentum.sql
â”‚       â”‚   â”‚   â”œâ”€â”€ rsi.sql
â”‚       â”‚   â”‚   â””â”€â”€ volatility.sql
â”‚       â”‚   â””â”€â”€ schema.yml                           # dbt Tests (unique, not null)
â”‚       â”œâ”€â”€ snapshots/
â”‚       â”‚   â””â”€â”€ stock_snapshot.sql                   # Tracks historical changes
â”‚       â”œâ”€â”€ dbt_project.yml                          # dbt config
â”‚       â””â”€â”€ profiles.yml                             # Snowflake credentials (Airflow)
â”‚
â”œâ”€â”€ docker-compose.yaml                              # Airflow + dbt environment
â””â”€â”€ README.md
